{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "417d5d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports for Task 2 ---\n",
    "import pandas as pd\n",
    "import talib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83f6f78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Task 2: Technical Analysis for configured stock symbols ---\n",
      "Will analyze symbols: TSLA, NVDA, META, AMZN, GOOG, AAPL, MSFT\n",
      "Data will be loaded from: d:\\Documents\\Projects\\10 Academy\\Stock Market\\financial-news-analysis\\data\n",
      "Plots will be saved to: d:\\Documents\\Projects\\10 Academy\\Stock Market\\financial-news-analysis\\Plots-task2\n"
     ]
    }
   ],
   "source": [
    "# Listing the stock symbols\n",
    "stock_symbols = ['TSLA', \"NVDA\", \"META\", \"AMZN\", \"GOOG\", \"AAPL\",\"MSFT\"]\n",
    "\n",
    "# data directory for the data\n",
    "Data_Dir = '../data/'\n",
    "\n",
    "# The directory where the plots will be placed\n",
    "Plots_Dir = '../Plots-task2'\n",
    "os.makedirs(Plots_Dir, exist_ok=True)\n",
    "\n",
    "#settinng ploting style\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# setup_logging('task2_analysis.log') # If you use your custom logging\n",
    "print(f\"--- Starting Task 2: Technical Analysis for configured stock symbols ---\")\n",
    "print(f\"Will analyze symbols: {', '.join(stock_symbols)}\")\n",
    "print(f\"Data will be loaded from: {os.path.abspath(Data_Dir)}\") # Shows the full path being used\n",
    "print(f\"Plots will be saved to: {os.path.abspath(Plots_Dir)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdb1d752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Keep your imports and initial configuration as they are)\n",
    "\n",
    "# --- Function to load and prepare data for a single stock ---\n",
    "def load_data(symbol, data_dir): # Renamed to match your function name\n",
    "    csv_filename = f\"{symbol}_historical_data.csv\"\n",
    "    csv_filepath = os.path.join(data_dir, csv_filename)\n",
    "    print(f\"\\nLoading: {symbol} from {csv_filepath}\")\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(csv_filepath)\n",
    "        if df.empty:\n",
    "            print(f\"  No data in {csv_filename}. Skipping.\")\n",
    "            return None\n",
    "\n",
    "        # --- Date Column Processing ---\n",
    "        possible_date_columns = ['Date', 'date', 'Datetime', 'timestamp', 'Timestamp']\n",
    "        date_col_name = None\n",
    "        for col_name_iter in possible_date_columns: # Renamed loop variable\n",
    "            if col_name_iter in df.columns:\n",
    "                date_col_name = col_name_iter\n",
    "                break\n",
    "        \n",
    "        if date_col_name is None:\n",
    "            print(f\"  Error: Date column not found in {csv_filename}. Available: {df.columns.tolist()}. Skipping.\")\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            df[date_col_name] = pd.to_datetime(df[date_col_name])\n",
    "            df.set_index(date_col_name, inplace=True)\n",
    "            print(f\"  Set '{date_col_name}' as DatetimeIndex for {symbol}.\")\n",
    "        except Exception as e_date:\n",
    "            print(f\"  Error processing date column '{date_col_name}' for {symbol}: {e_date}. Skipping.\")\n",
    "            return None\n",
    "\n",
    "        # --- OHLCV Column Renaming and Selection ---\n",
    "        print(f\"  Initial columns for {symbol}: {df.columns.tolist()}\") # DEBUG: See original columns\n",
    "\n",
    "        # ** YOU MUST ADJUST THIS MAP BASED ON YOUR CSVs **\n",
    "        # This map should take your *actual current column names* and map them to the *desired standard names*.\n",
    "        column_rename_map = {\n",
    "            # 'Original Open Name': 'Open',\n",
    "            # 'Original High Name': 'High',\n",
    "            # 'Original Low Name': 'Low',\n",
    "            # 'Adj Close': 'Close', # Only if you want 'Adj Close' to *become* 'Close'\n",
    "            # 'Original Volume Name': 'Volume',\n",
    "        }\n",
    "\n",
    "        # Decide which 'Close' to use if multiple exist (e.g., 'Close' and 'Adj Close')\n",
    "        # Preference: Use 'Adj Close' as 'Close' if available. If not, use 'Close' if available.\n",
    "        if 'Adj Close' in df.columns:\n",
    "            if 'Close' in df.columns and 'Adj Close' != 'Close': # If 'Close' also exists and is different\n",
    "                print(f\"  Both 'Close' and 'Adj Close' found for {symbol}. Prioritizing 'Adj Close' and renaming it to 'Close'. Dropping original 'Close'.\")\n",
    "                df.drop(columns=['Close'], inplace=True, errors='ignore') # Drop original 'Close' if it exists\n",
    "            column_rename_map['Adj Close'] = 'Close'\n",
    "        elif 'Close' in df.columns:\n",
    "            print(f\"  'Close' column found for {symbol}. Will use it as is.\")\n",
    "            # No rename needed if 'Close' is already the target name and it exists\n",
    "        else:\n",
    "            print(f\"  Error: Neither 'Close' nor 'Adj Close' found for {symbol}. Cannot determine closing price. Skipping.\")\n",
    "            return None\n",
    "            \n",
    "        # Rename other columns if necessary (Open, High, Low, Volume)\n",
    "        # Example: if your open price is 'Open Price'\n",
    "        # if 'Open Price' in df.columns: column_rename_map['Open Price'] = 'Open'\n",
    "        # Add similar logic for High, Low, Volume based on your CSVs.\n",
    "\n",
    "        df.rename(columns=column_rename_map, inplace=True)\n",
    "        print(f\"  Columns after rename for {symbol}: {df.columns.tolist()}\") # DEBUG: See columns after rename\n",
    "\n",
    "        required_cols = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "        \n",
    "        # Ensure standard columns exist after renaming, potentially renaming lowercase versions\n",
    "        for req_col in required_cols:\n",
    "            if req_col not in df.columns and req_col.lower() in df.columns:\n",
    "                df.rename(columns={req_col.lower(): req_col}, inplace=True)\n",
    "                print(f\"  Renamed lowercase '{req_col.lower()}' to '{req_col}' for {symbol}.\")\n",
    "        \n",
    "        print(f\"  Columns before final selection for {symbol}: {df.columns.tolist()}\") # DEBUG\n",
    "\n",
    "        # Check for duplicate column names *before* selection, especially for 'Close'\n",
    "        if isinstance(df.columns, pd.MultiIndex):\n",
    "            print(f\"  Warning: DataFrame has a MultiIndex for columns for {symbol}. This is unexpected.\")\n",
    "        elif df.columns.duplicated().any():\n",
    "            print(f\"  Warning: Duplicate column names found for {symbol} BEFORE final selection: {df.columns[df.columns.duplicated()].tolist()}\")\n",
    "            # Attempt to resolve: keep first occurrence if duplicates are an issue for selection\n",
    "            # This is a basic fix; ideally, the renaming logic should prevent duplicates of required_cols\n",
    "            df = df.loc[:, ~df.columns.duplicated(keep='first')]\n",
    "            print(f\"    Attempted to remove duplicate columns, keeping first. New columns: {df.columns.tolist()}\")\n",
    "\n",
    "\n",
    "        missing_final_cols = [col for col in required_cols if col not in df.columns]\n",
    "        if missing_final_cols:\n",
    "            print(f\"  Error: Missing required OHLCV columns for {symbol} after all processing: {missing_final_cols}. Available: {df.columns.tolist()}. Skipping.\")\n",
    "            return None\n",
    "        \n",
    "        # Select only the standardized columns to ensure order and uniqueness for these 5\n",
    "        df_selected = df[required_cols].copy() # Use a new variable for clarity\n",
    "\n",
    "        df_selected.sort_index(inplace=True) # Sort by date\n",
    "\n",
    "        # --- Missing Value Handling & Type Conversion ---\n",
    "        for col in required_cols: # Iterate over the known unique required_cols\n",
    "            # df_selected[col] should now always be a Series\n",
    "            if col not in df_selected.columns: # Should not happen if previous checks are good\n",
    "                print(f\"  Critical error: Column {col} missing before to_numeric for {symbol}. This indicates a logic flaw.\")\n",
    "                return None\n",
    "\n",
    "            df_selected[col] = pd.to_numeric(df_selected[col], errors='coerce') # This is where the error occurred\n",
    "            \n",
    "            if df_selected[col].isnull().any():\n",
    "                print(f\"  Column '{col}' in {symbol} has NaNs. Filling...\")\n",
    "                df_selected[col].fillna(method='ffill', inplace=True)\n",
    "                df_selected[col].fillna(method='bfill', inplace=True)\n",
    "\n",
    "        df_selected.dropna(subset=required_cols, inplace=True)\n",
    "\n",
    "        if df_selected.empty:\n",
    "            print(f\"  No valid data remaining for {symbol} after cleaning. Skipping.\")\n",
    "            return None\n",
    "\n",
    "        print(f\"  Successfully prepared data for {symbol}. Shape: {df_selected.shape}\")\n",
    "        return df_selected # Return the selected and cleaned DataFrame\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"  Error: File not found: {csv_filepath}. Skipping.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"  Outer Error loading or processing {symbol}: {e}. Skipping.\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "841d43d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading: TSLA from ../data/TSLA_historical_data.csv\n",
      "  Set 'Date' as DatetimeIndex for TSLA.\n",
      "  Initial columns for TSLA: ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'Dividends', 'Stock Splits']\n",
      "  Both 'Close' and 'Adj Close' found for TSLA. Prioritizing 'Adj Close' and renaming it to 'Close'. Dropping original 'Close'.\n",
      "  Columns after rename for TSLA: ['Open', 'High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits']\n",
      "  Columns before final selection for TSLA: ['Open', 'High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits']\n",
      "  Successfully prepared data for TSLA. Shape: (3545, 5)\n",
      "\n",
      "Loading: NVDA from ../data/NVDA_historical_data.csv\n",
      "  Set 'Date' as DatetimeIndex for NVDA.\n",
      "  Initial columns for NVDA: ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'Dividends', 'Stock Splits']\n",
      "  Both 'Close' and 'Adj Close' found for NVDA. Prioritizing 'Adj Close' and renaming it to 'Close'. Dropping original 'Close'.\n",
      "  Columns after rename for NVDA: ['Open', 'High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits']\n",
      "  Columns before final selection for NVDA: ['Open', 'High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits']\n",
      "  Successfully prepared data for NVDA. Shape: (6421, 5)\n",
      "\n",
      "Loading: META from ../data/META_historical_data.csv\n",
      "  Set 'Date' as DatetimeIndex for META.\n",
      "  Initial columns for META: ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'Dividends', 'Stock Splits']\n",
      "  Both 'Close' and 'Adj Close' found for META. Prioritizing 'Adj Close' and renaming it to 'Close'. Dropping original 'Close'.\n",
      "  Columns after rename for META: ['Open', 'High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits']\n",
      "  Columns before final selection for META: ['Open', 'High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits']\n",
      "  Successfully prepared data for META. Shape: (2926, 5)\n",
      "\n",
      "Loading: AMZN from ../data/AMZN_historical_data.csv\n",
      "  Set 'Date' as DatetimeIndex for AMZN.\n",
      "  Initial columns for AMZN: ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'Dividends', 'Stock Splits']\n",
      "  Both 'Close' and 'Adj Close' found for AMZN. Prioritizing 'Adj Close' and renaming it to 'Close'. Dropping original 'Close'.\n",
      "  Columns after rename for AMZN: ['Open', 'High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits']\n",
      "  Columns before final selection for AMZN: ['Open', 'High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits']\n",
      "  Successfully prepared data for AMZN. Shape: (6846, 5)\n",
      "\n",
      "Loading: GOOG from ../data/GOOG_historical_data.csv\n",
      "  Set 'Date' as DatetimeIndex for GOOG.\n",
      "  Initial columns for GOOG: ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'Dividends', 'Stock Splits']\n",
      "  Both 'Close' and 'Adj Close' found for GOOG. Prioritizing 'Adj Close' and renaming it to 'Close'. Dropping original 'Close'.\n",
      "  Columns after rename for GOOG: ['Open', 'High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits']\n",
      "  Columns before final selection for GOOG: ['Open', 'High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits']\n",
      "  Successfully prepared data for GOOG. Shape: (5020, 5)\n",
      "\n",
      "Loading: AAPL from ../data/AAPL_historical_data.csv\n",
      "  Set 'Date' as DatetimeIndex for AAPL.\n",
      "  Initial columns for AAPL: ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'Dividends', 'Stock Splits']\n",
      "  Both 'Close' and 'Adj Close' found for AAPL. Prioritizing 'Adj Close' and renaming it to 'Close'. Dropping original 'Close'.\n",
      "  Columns after rename for AAPL: ['Open', 'High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits']\n",
      "  Columns before final selection for AAPL: ['Open', 'High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits']\n",
      "  Successfully prepared data for AAPL. Shape: (10998, 5)\n",
      "\n",
      "Loading: MSFT from ../data/MSFT_historical_data.csv\n",
      "  Set 'Date' as DatetimeIndex for MSFT.\n",
      "  Initial columns for MSFT: ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'Dividends', 'Stock Splits']\n",
      "  Both 'Close' and 'Adj Close' found for MSFT. Prioritizing 'Adj Close' and renaming it to 'Close'. Dropping original 'Close'.\n",
      "  Columns after rename for MSFT: ['Open', 'High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits']\n",
      "  Columns before final selection for MSFT: ['Open', 'High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits']\n",
      "  Successfully prepared data for MSFT. Shape: (9672, 5)\n",
      "\n",
      "Data loaded for 7 stocks: ['TSLA', 'NVDA', 'META', 'AMZN', 'GOOG', 'AAPL', 'MSFT']\n"
     ]
    }
   ],
   "source": [
    "# === BLOCK 3: LOAD DATA FOR ALL SYMBOLS ===\n",
    "all_stocks_data = {}\n",
    "for sym_iter in stock_symbols: # Changed loop variable\n",
    "    # Call load_data without date filter arguments\n",
    "    stock_df_loaded = load_data(sym_iter, Data_Dir) # Changed variable name\n",
    "    if stock_df_loaded is not None and not stock_df_loaded.empty:\n",
    "        all_stocks_data[sym_iter] = stock_df_loaded\n",
    "\n",
    "if not all_stocks_data:\n",
    "    print(\"\\nNo stock data loaded successfully. Exiting script.\")\n",
    "    # exit() # Comment out exit() during debugging to see full output for all files\n",
    "else:\n",
    "    print(f\"\\nData loaded for {len(all_stocks_data)} stocks: {list(all_stocks_data.keys())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be29503e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- Processing: TSLA ---\n",
      "  Calculating TA indicators for TSLA...\n",
      "  Indicators calculated for TSLA.\n",
      "  Plotting Price & SMAs for TSLA...\n",
      "  Plotting RSI for TSLA...\n",
      "  Plotting MACD for TSLA...\n",
      "\n",
      "\n",
      "--- Processing: NVDA ---\n",
      "  Calculating TA indicators for NVDA...\n",
      "  Indicators calculated for NVDA.\n",
      "  Plotting Price & SMAs for NVDA...\n",
      "  Plotting RSI for NVDA...\n",
      "  Plotting MACD for NVDA...\n",
      "\n",
      "\n",
      "--- Processing: META ---\n",
      "  Calculating TA indicators for META...\n",
      "  Indicators calculated for META.\n",
      "  Plotting Price & SMAs for META...\n",
      "  Plotting RSI for META...\n",
      "  Plotting MACD for META...\n",
      "\n",
      "\n",
      "--- Processing: AMZN ---\n",
      "  Calculating TA indicators for AMZN...\n",
      "  Indicators calculated for AMZN.\n",
      "  Plotting Price & SMAs for AMZN...\n",
      "  Plotting RSI for AMZN...\n",
      "  Plotting MACD for AMZN...\n",
      "\n",
      "\n",
      "--- Processing: GOOG ---\n",
      "  Calculating TA indicators for GOOG...\n",
      "  Indicators calculated for GOOG.\n",
      "  Plotting Price & SMAs for GOOG...\n",
      "  Plotting RSI for GOOG...\n",
      "  Plotting MACD for GOOG...\n",
      "\n",
      "\n",
      "--- Processing: AAPL ---\n",
      "  Calculating TA indicators for AAPL...\n",
      "  Indicators calculated for AAPL.\n",
      "  Plotting Price & SMAs for AAPL...\n",
      "  Plotting RSI for AAPL...\n",
      "  Plotting MACD for AAPL...\n",
      "\n",
      "\n",
      "--- Processing: MSFT ---\n",
      "  Calculating TA indicators for MSFT...\n",
      "  Indicators calculated for MSFT.\n",
      "  Plotting Price & SMAs for MSFT...\n",
      "  Plotting RSI for MSFT...\n",
      "  Plotting MACD for MSFT...\n",
      "\n",
      "--- Task 2 Finished. Plots saved in d:\\Documents\\Projects\\10 Academy\\Stock Market\\financial-news-analysis\\Plots-task2 ---\n"
     ]
    }
   ],
   "source": [
    "# === BLOCK 4: CALCULATE INDICATORS AND PLOT FOR EACH STOCK ===\n",
    "# (This block should work if load_data returns correctly structured DataFrames)\n",
    "# Make sure to use the correct DataFrame variable from the loop (e.g., df_stock from your previous version)\n",
    "\n",
    "for symbol_loop_var, df_stock_loop_var in all_stocks_data.items(): # Changed loop variables\n",
    "    print(f\"\\n\\n--- Processing: {symbol_loop_var} ---\")\n",
    "\n",
    "    # --- Calculate TA-Lib Indicators ---\n",
    "    try:\n",
    "        print(f\"  Calculating TA indicators for {symbol_loop_var}...\")\n",
    "        df_stock_loop_var['SMA_20'] = talib.SMA(df_stock_loop_var['Close'], timeperiod=20)\n",
    "        df_stock_loop_var['SMA_50'] = talib.SMA(df_stock_loop_var['Close'], timeperiod=50)\n",
    "        df_stock_loop_var['SMA_200'] = talib.SMA(df_stock_loop_var['Close'], timeperiod=200) if len(df_stock_loop_var) >= 200 else pd.NA\n",
    "        \n",
    "        df_stock_loop_var['RSI_14'] = talib.RSI(df_stock_loop_var['Close'], timeperiod=14)\n",
    "        \n",
    "        macd, macdsignal, macdhist = talib.MACD(df_stock_loop_var['Close'], fastperiod=12, slowperiod=26, signalperiod=9)\n",
    "        df_stock_loop_var['MACD'] = macd\n",
    "        df_stock_loop_var['MACD_Signal'] = macdsignal\n",
    "        df_stock_loop_var['MACD_Hist'] = macdhist\n",
    "        print(f\"  Indicators calculated for {symbol_loop_var}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Error calculating TA indicators for {symbol_loop_var}: {e}. Skipping plots for this stock.\")\n",
    "        indicator_cols = ['SMA_20', 'SMA_50', 'SMA_200', 'RSI_14', 'MACD', 'MACD_Signal', 'MACD_Hist']\n",
    "        for ind_col in indicator_cols: \n",
    "            if ind_col not in df_stock_loop_var.columns: df_stock_loop_var[ind_col] = pd.NA\n",
    "        \n",
    "    # --- Plotting (ensure df_stock_loop_var is used) ---\n",
    "    # Plot 1: Price and SMAs\n",
    "    print(f\"  Plotting Price & SMAs for {symbol_loop_var}...\")\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    plt.plot(df_stock_loop_var.index, df_stock_loop_var['Close'], label='Close Price', color='blue', alpha=0.7)\n",
    "    if 'SMA_20' in df_stock_loop_var.columns and not df_stock_loop_var['SMA_20'].isnull().all():\n",
    "        plt.plot(df_stock_loop_var.index, df_stock_loop_var['SMA_20'], label='SMA 20', color='orange', ls='--')\n",
    "    if 'SMA_50' in df_stock_loop_var.columns and not df_stock_loop_var['SMA_50'].isnull().all():\n",
    "        plt.plot(df_stock_loop_var.index, df_stock_loop_var['SMA_50'], label='SMA 50', color='green', ls='--')\n",
    "    if 'SMA_200' in df_stock_loop_var.columns and not df_stock_loop_var['SMA_200'].isnull().all():\n",
    "        plt.plot(df_stock_loop_var.index, df_stock_loop_var['SMA_200'], label='SMA 200', color='red', ls='--')\n",
    "    plt.title(f'{symbol_loop_var} Closing Price & Moving Averages')\n",
    "    plt.xlabel('Date'); plt.ylabel('Price')\n",
    "    plt.legend(); plt.grid(True); plt.tight_layout()\n",
    "    plt.savefig(os.path.join(Plots_Dir, f'{symbol_loop_var}_price_sma.png')); plt.close()\n",
    "\n",
    "    # Plot 2: RSI\n",
    "    if 'RSI_14' in df_stock_loop_var.columns and not df_stock_loop_var['RSI_14'].isnull().all():\n",
    "        print(f\"  Plotting RSI for {symbol_loop_var}...\")\n",
    "        plt.figure(figsize=(14, 5))\n",
    "        plt.plot(df_stock_loop_var.index, df_stock_loop_var['RSI_14'], label='RSI 14', color='purple')\n",
    "        plt.axhline(70, color='red', ls='--', alpha=0.5, label='Overbought (70)')\n",
    "        plt.axhline(30, color='green', ls='--', alpha=0.5, label='Oversold (30)')\n",
    "        plt.fill_between(df_stock_loop_var.index, 70, 100, color='red', alpha=0.1)\n",
    "        plt.fill_between(df_stock_loop_var.index, 0, 30, color='green', alpha=0.1)\n",
    "        plt.title(f'{symbol_loop_var} Relative Strength Index (RSI)')\n",
    "        plt.xlabel('Date'); plt.ylabel('RSI Value (0-100)')\n",
    "        plt.ylim(0, 100); plt.legend(); plt.grid(True); plt.tight_layout()\n",
    "        plt.savefig(os.path.join(Plots_Dir, f'{symbol_loop_var}_rsi.png')); plt.close()\n",
    "    else:\n",
    "        print(f\"  RSI data for {symbol_loop_var} not plotted (column missing or all NA).\")\n",
    "\n",
    "    # Plot 3: MACD\n",
    "    if 'MACD' in df_stock_loop_var.columns and not df_stock_loop_var['MACD'].isnull().all():\n",
    "        print(f\"  Plotting MACD for {symbol_loop_var}...\")\n",
    "        fig, axes = plt.subplots(2, 1, figsize=(14, 8), sharex=True, gridspec_kw={'height_ratios': [2, 1]})\n",
    "        \n",
    "        axes[0].plot(df_stock_loop_var.index, df_stock_loop_var['MACD'], label='MACD', color='blue')\n",
    "        axes[0].plot(df_stock_loop_var.index, df_stock_loop_var['MACD_Signal'], label='Signal Line', color='red', ls='--')\n",
    "        axes[0].set_ylabel('MACD Value'); axes[0].legend(loc='upper left'); axes[0].grid(True)\n",
    "\n",
    "        hist_colors = ['green' if val >= 0 else 'red' for val in df_stock_loop_var['MACD_Hist'].fillna(0)]\n",
    "        axes[1].bar(df_stock_loop_var.index, df_stock_loop_var['MACD_Hist'], label='MACD Histogram', color=hist_colors, alpha=0.7, width=1.0)\n",
    "        axes[1].axhline(0, color='grey', ls='--', lw=0.8)\n",
    "        axes[1].set_xlabel('Date'); axes[1].set_ylabel('MACD Histogram'); axes[1].legend(loc='upper left'); axes[1].grid(True)\n",
    "\n",
    "        fig.suptitle(f'{symbol_loop_var} MACD Analysis', fontsize=16)\n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "        plt.savefig(os.path.join(Plots_Dir, f'{symbol_loop_var}_macd.png')); plt.close()\n",
    "    else:\n",
    "        print(f\"  MACD data for {symbol_loop_var} not plotted (column missing or all NA).\")\n",
    "\n",
    "print(f\"\\n--- Task 2 Finished. Plots saved in {os.path.abspath(Plots_Dir)} ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
